---
title: "网络编程"
description: 
date: 2023-09-06T14:07:35+08:00
image:
url: /network
math: true
comments: false
draft: false
categories:
  - go
---

# OSI7层模型

- 应用层
- 表示层
- 会话层
- 传输层
- 网络层
- 数据链路层
- 物理层

**五层模型**

- 应用层
- 传输层
- 网络层
- 数据链路层
- 物理层


# 应用层

## HTTP

### 常见的HTTP状态码

- 1XX: 信息状态码,请求正在被处理
- 2XX: 成功状态码,请求正常处理完毕
- 3XX: 重定向状态码,需要进行附加操作以完成请求
- 4XX: 客户端错误状态码,服务器无法处理请求
- 5XX: 服务器错误状态码,服务器处理请求出错

### HTTP和HTTPS之间的区别

HTTP的默认端口是80,HTTPS的默认端口是443

HTTPS会通过TLS对报文进行加密

#### 密码学相关介绍

**加密分为对称加密和非对称加密**

在对称加密中，用于加密和解密的密钥是相同的，这种加密方式的优点是加密和解密的速度快，缺点是密钥的传输和管理比较困难。

在非对称加密中,存在一把公钥$K^+$和私钥$K^-$,而且公钥可以随意公开。公钥可以用来解密私钥加密的内容,私钥可以用来解密公钥加密的内容。

使用Alice和Bob的例子说明,加入Alice想要向Bob发送消息m,那么Alice首先需要获取Bob的公钥$K^+$,然后用$K^+$加密m,然后发送给Bob,然后Bob用自己的私钥$K^-$解密m。

该流程可以保证消息m只能被Bob解密,因为只有Bob有自己的私钥$K^-$。

但是该流程还是存在缺点的,因此整体加密加密过程都是公开的,因此入侵者据此构造消息直接发起明文攻击和假消息。即发送方的身份无法确定，解决这个问题需要`数字签名`技术

RSA算法目前几乎就是公开密钥密码的代名词。但是因为一般RSA的加密解密速度很慢，因此需要将RSA和对称加密结合起来使用。使用RSA来传递对称密钥, 然后使用对称密钥来加密数据。

**报文完整性**

报文完整性的保证是通过散列函数+发送方和接收方共享的鉴别密钥s来完成的

Alice向Bob发送消息

step1. Alice生成报文$m$,并用$s$串联$m$,然后用散列函数$h$,生成$h(m+s)$,发送内容$(m,h(m+s))$,其中$h(m+s)$被称为报文鉴别码(Message Authentication Code,MAC)

step2. Bob收到消息$(m,h(m+s))$，然后用$s$串联$m$,然后用散列函数$h$,生成$h'(m+s)$,对比自己计算得到和收到的散列值,既可确定报文完整性

在这这其中密钥s是必须的,否则任何人都可以伪造消息,至于s的分发，可以通过物理接触的方式分发

**数字签名**

使用自己的私钥加密报文, 当面对$(m, K^-(m))$时,如果$m = K^+(K^-(m))$,则证明了报文的完整性和源。
不过因为非对称加密的速度慢,因此可以考虑引入散列函数对散列结果签名

>MAC和数字签名之前的区别,MAC和数字签名都可以用来验证报文完整性和源,但是MAC没有使用任何的加密技术,但 是需要一个共享的密钥s。而数字签名使用了非对称加密技术,因此不需要共享密钥,但是速度慢

**公钥认证**

数字签名的一个重要应用就是公钥认证，上述数字签名的问题存在的问题是需要假定 $k^+_B$和Bob的身份是绑定的,否则任何一个人都是声称自己是Bob然后使用自己的公钥和私钥伪装Bob。解决这个问题引入的就是认证中心(CA)

CA是一个第三方完全可信的机构,CA具有以下三个作用
1. CA证实一个实体的真实身份
2. 一旦CA验证了某个实体的身份,CA会生成一个将其身份和公钥绑定的证书，并且CA会用自己的私钥对证书进行签名，一般各个CA的公钥已经是内置在计算机中的保证绝对可信的,因此可以用CA的公钥来验证证书的完整性和来源

#### TLS握手

SSL采用 机密性,完整性,服务器鉴别和客户端鉴别这4个方面来强化TCP


1. 握手
   - (1) 客户发送它支持的密码算法的列表,连同一个客户的不重数
   - (2) 服务器选择一种对称算法,一种公钥算法和一种MAC算法,然后发送自己的选择,自己的证书,连同一个服务器的不重数
   - (3) 客户端验证该证书,提取服务器的公钥,生成一个前主密钥(PMS),用服务器的公钥加密PMS,然后发送给服务器
   - (4) 使用相同的密钥导出函数,客户端和服务器独立地从PMS和不重数种计算出主密钥(MS),切后切分成两个密码和两个MAC密钥
   - (5) 客户端发送所有握手报文地一个MAC
   - (6) 服务器端发送所有握手报文的一个MAC
  (5),(6) 步骤用于验证握手过程没有被篡改

2. 连接关闭
   SSL记录中会在类型字段指明该记录用户终止该SSL会话,不能直接使用TCP FIN报文终止连接,因为这样会导致中间人攻击

## cookie和session

Cookie存放在客户端,一般用来保存用户信息。

Cookie的作用
1. 我们在 `Cookie` 中保存已经登录过的用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了。除此之外，`Cookie` 还能保存用户首选项，主题和其他设置信息。
2. 使用`Cookie`保存`SessionID`或者`Token`,向后端发送请求时带上`Cookie`,这样后端就能获取到`SessionID`或者`Token`,然后根据`SessionID`或者`Token`获取用户信息。
3. `Cookie` 还可以用来记录和分析用户行为。举个简单的例子你在网上购物的时候，因为 HTTP 协议是没有状态的，如果服务器想要获取你在某个页面的停留状态或者看了哪些商品，一种常用的实现方式就是将这些信息存放在`Cookie`

Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

使用`Session-Cookie`方案进行身份验证

很多时候我们都是通过 `SessionID` 来实现特定的用户，`SessionID` 一般会选择存放在 `Redis` 中。

举个例子：

(1) 用户成功登陆系统，然后返回给客户端对应 SessionID 的 Cookie 。

(2) 当用户向后端发起请求的时候会把 SessionID 带上，这样后端就知道用户的身份状态了。

多服务器节点下的Session-Cookie方案
几个可供参考的解决方案

1. 通过特定的哈希策略,保证某个用户的所有请求都转发给同一个服务器处理,每个服务器均保存一部分用户的session信息

一致性哈希(consistent hashing)就可以帮助建立这种映射

[一致性哈希算法（consistent hashing）](https://zhuanlan.zhihu.com/p/129049724)

确定一个哈希函数的散列值的范围

把对象和服务器均通过散列函数散列到这个环上,对象的对应存储节点是顺时针的第一个服务器节点,这种哈希方式当面临服务器节点增加或者减少时,只需要在两个服务器节点之间转移数据,可以优先减轻集群压力


2. 服务器同步所有的session信息,冗余多,通信代价大
3. 额外使用一个集群(or服务器)保存session信息(Redis),然后所有的服务器都去这个集群(or服务器)中获取session信息

## jwt鉴权

JWT(JSON Web Token)是一种基于Token的认证授权机制

JWT的组成部分
1. Header,描述jwt的元数据,通常包含两部分,token的类型和使用的加密算法
2. Payload,存放实际传递的数据
3. Signature, 服务器通过Payload,Header和一个密钥(Secret),使用Header中指定的签名算法生成的

JWT的通常表示形式为xxxx.yyyyy.zzzzz,每一部分都是用Base64编码的

**Header**
Header 通常由两部分组成：

- typ（Type）：令牌类型，也就是 JWT。
- alg（Algorithm）：签名算法，比如 HS256。
- 
  ```json
  {
    "alg": "HS256",
    "typ": "JWT"
  }
  ```
JSON 形式的 Header 被转换成 Base64 编码，成为 JWT 的第一部分。

**Payload**
Payload 也是 JSON 格式数据，其中包含了 Claims(声明，包含 JWT 的相关信息)。Claims 有三种类型：
- Registered Claims：这些声明是预先定义的，包括 iss（签发者）、exp（过期时间）、sub（主题）等。
- Public Claims：JWT签发方可以自定义的声明
- Private Claims：JWT 签发方因为项目需要而自定义的声明，更符合实际项目场景使用。

**Signature**
Signature 部分是对前两部分的签名，作用是防止 JWT（主要是 payload） 被篡改。
(m,h(m+s))

jwt可以看成是一种数字签名技术

无论何时用户想要访问受保护的路由或者资源的时候，用户代理（通常是浏览器）都应该带上JWT，典型的，通常放在Authorization header中，用Bearer schema。

header应该看起来是这样的：
`Authorization: Bearer`

服务器上的受保护的路由将会检查Authorization header中的JWT是否有效，如果有效，则用户可以访问受保护的资源。如果JWT包含足够多的必需的数据，那么就可以减少对某些操作的数据库查询的需要，尽管可能并不总是如此。

token撤销问题

JWT发放出去之后就无法管控了,处理服务器自己保存对应的状态,但是这又违背了JWT的本意

## SSO(单点登录)

SSO(Single Sign On)即单点登录是说用户登录多个子系统中的一个,然后就有权访问与其相关的其他系统

## 跨域问题

## HTTP/1.0 to HTTP/1.1 to HTTP/2.0

**HTTP/1.0**

1. 默认短连接
2. 状态码较少,不支持断点续传
3. 缓存机制,主要使用If-Modified-Since和Expires
4. Host头处理 HTTP/1.1 引入了 Host 头字段，允许在同一 IP 地址上托管多个域名，从而支持虚拟主机的功能。
   
**HTTP/1.1**

1. 默认长连接

2. 支持断点续传(206状态码和 Range字段)

3. HTTP1.1支持请求管道化（pipelining）。

基于HTTP1.1的长连接，使得请求管线化成为可能。 管线化使得请求能够“并行”传输。
例如：假如响应的主体是一个html页面，页面中包含了很多img，这个时候keep-alive就了很大作用。能够“并行”发送多个请求。（注意，这里的“并行”并不是真正意义上的并行传输）
需要注意的是：服务器必须按照客户端请求的先后顺序依次回送相应的结果，以保证客户端能够区分出每次请求的响应内容。
也就是说，HTTP管道化可以让我们把先进先出队列从客户端（请求队列）迁移到服务端（响应队列）

真并行传输 — 浏览器优化策略
HTTP1.1支持管道化，但是服务器也必须进行逐个响应的送回，这个是很大的一个缺陷。
实际上，现阶段的浏览器厂商采取了另外一种做法，它允许我们打开多个TCP的会话，也就是说，上图我们看到的并行，其实是不同的TCP连接上的HTTP请求和相应。这才是真正的并行！

**HTTP/2.0**

1. 二进制分帧: HTTP/2.0 采用二进制格式传输数据，而 HTTP/1.1 是文本格式。二进制格式的优势在于，二进制格式的解析速度更快，而且更加紧凑，减少了数据传输的大小。

2. 多路复用
  - 流(stream):指已经建立连接的双向字节流
  - 消息:与逻辑消息对应的完整的一系列数据帧
  - 帧(frame):HTTP/2.0通信的最小单位，每个帧包含一个特定的头部，至少包含一个流标识符(stream_id)
  
  每个数据流以消息的形式发送，而消息由一或多个帧组成。这些帧可以乱序发送，然后再根据每个帧头部的流标识符（Stream_id）重新封装。

3. 首部压缩：HTTP/2.0 使用 HPACK 算法对首部进行压缩，减少了数据传输的大小。而HTTP/1.1只能对Body压缩
 
4. 服务器推送（Server Push）：HTTP/2.0 支持服务器推送，可以在客户端请求一个资源时，将其他相关资源一并推送给客户端，而无需客户端明确的需求。从而减少了客户端的请求次数和延迟。而 HTTP/1.1 需要客户端自己发送请求来获取相关资源。

`If-Modified-Since` 是一个条件式请求首部，服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为`200` 。如果请求的资源从那时起未经修改，那么返回一个不带有消息主体的 `304` 响应，而在 `Last-Modified` 首部中会带有上次修改时间。


# WebSocket

WebSocket 是一种基于 TCP 连接的全双工通信协议，即客户端和服务器可以同时发送和接收数据。

1. WebSocket 是一种双向实时通信协议，而 HTTP 是一种单向通信协议。并且，HTTP 协议下的通信只能由客户端发起，服务器无法主动通知客户端。
2. WebSocket 使用 ws:// 或 wss://（使用 SSL/TLS 加密后的协议，类似于 HTTP 和 HTTPS 的关系） 作为协议前缀，HTTP 使用 http:// 或 https:// 作为协议前缀。
3. WebSocket 可以支持扩展，用户可以扩展协议，实现部分自定义的子协议，如支持压缩、加密等。
4. WebSocket 通信数据格式比较轻量，用于协议控制的数据包头部相对较小，网络开销小，而 HTTP 通信每次都要携带完整的头部，网络开销较大（HTTP/2.0 使用二进制帧进行数据传输，还支持头部压缩，减少了网络开销）

WebSocket的工作流程

1. 客户端向服务器发送一个`HTTP`请求，请求头中包含`Upgrade: websocket`和`Sec-WebSocket-Key` 等字段，表示要求升级协议为`WebSocket`；
2. 服务器收到这个请求后，会进行升级协议的操作，如果支持 `WebSocket`，它将回复一个`HTTP 101`状态码，响应头中包含 ，`Connection: Upgrade和 Sec-WebSocket-Accept: xxx `等字段、表示成功升级到`WebSocket`协议。
3. 客户端和服务器之间建立了一个`WebSocket`连接，可以进行双向的数据传输。数据以帧（frames）的形式进行传送，WebSocket 的每条消息可能会被切分成多个数据帧（最小单位）。发送端会将消息切割成多个帧发送给接收端，接收端接收消息帧，并将关联的帧重新组装成完整的消息。
4. 客户端或服务器可以主动发送一个关闭帧，表示要断开连接。另一方收到后，也会回复一个关闭帧，然后双方关闭 TCP 连接。
5. 另外，建立 WebSocket 连接之后，通过心跳机制来保持 WebSocket 连接的稳定性和活跃性。

# 常见面试问题

1. 从用户输入一个url到html页面展示出来的全过程介绍

2. 通过DNS获取对应域名的ip
3. 浏览器向web服务器发送HTTP请求
4. HTTP请求下发到对应TCP请求
5. TCP通过三次握手首先先和服务器建立连接
6. TCP发送包装了对应http报文的数据包
7. 数据包下发到ip层,IP数据包在不同的路由器之间传输使用OSPF协议(Open Shortest Path First开放最短路径优先)
8. 转到数据链路层,ip包只拥有目的地的ip,需要使用arp协议解析出目的地的mac地址

arp协议概述: 主机发送信息时将包含目标IP地址的ARP请求广播到局域网络上的所有主机，并接收返回消息，以此确定目标的物理地址；收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。

# 传输层

## TCP连接

### TCP三次握手和四次挥手

看这个需要先看TCP的报文中的几个标志位：

![](2023-09-06-14-11-52.png)

- **ACK** 确认标志位，表明该报文是确认报文
- **SYN** 同步标志位，表明该报文时用来建立会话连接的
- **FIN** 结束标志位，表示我已经没有数据可以发送了了，即将关闭连接
- RST 重置标志位，用于连接复位，拒绝错误和非法的数据包

和连接建立有关的内容
- seq 序号
- ack 确认号

#### 三次握手

![](2023-09-06-14-15-07.png)

- 第一次握手：客户端发送要求建立TCP连接的报文,并且客户端会自己确定一个seq=J (SYN=1,seq=J)。如果没有收到服务器端的回应，表示丢包，则需要重新发送
- 第二次握手：服务器端受到第一次握手的报文，然后表明同意建立连接，因此发送确认报文，同时也将自己端建立连接的报文合并，服务器也需要自己确认一个序号=K
(ACK=1,SYN=1,seq=K,ack=J+1)
如果服务器端没有收到回应，则需要重发该报文
- 第三次握手：客户端受到第二次握手的报文，向服务器端回应
(ACK=1,ack=K+1)

然后连接就可以建立了

在后续数据传输过程中
1. client自己定义了一个seq=J,确定了server的目前的ack=K+1
2. server自定定义了一个seq=K,确定了client目前的ack=J+1
  
然后在client发送数据的时候, 发送的报文
**常见问题**
1. 为什么需要三次握手，两次不行吗？
  
  答：根据上面的描述，在第二次握手之后，如果服务器端收不到回应，则服务器端无法确定连接是否建立。
  如果只用两次握手，那么第三次握手丢包的话，服务器端则会变成一直等待接受数据的状态，但是因此客户端没有收到第二次握手的报文，因此客户端不会发送任何数据。

#### 四次挥手

![](2023-09-06-14-26-30.png)

- 第一次挥手：客户端发送一个FIN报文,表示不再发送数据(FIN=1,seq=u)
  FIN_WAIT_1:等待服务器端的ACK报文回应
- 第二次挥手：服务器端收到FIN之后，发送ACK报文(ACK=1,seq=v,ack=u+1),此时服务端进入CLOSE_WAIT状态，只可能发送数据，而不在接受数据。
- 第三次挥手：当服务器没有数据要发送之后，服务器端发送FIN报文(FIN=1,seq=w,ack=u+1),此时服务器端进入LAST_ACK状态,等待客户端的ACK报文回应
- 第四次挥手：客户端收到FIN报文之后，发送ACK报文(ACK=1,seq=u+1,ack=w+1),此时客户端进入TIME_WAIT状态，**等待2MSL之后**，如果没有异常情况，则可以关闭连接。
服务器端在收到客户端的ACK报文之后就可以关闭连接。

**常见问题**

为什么TIME_WAIT状态需要等待2MSL之后才能关闭连接？

2MSL是两倍的最大报文段生存时间，这是为了防止最后一个ACK报文丢失，导致服务器端无法关闭连接。客户端的ACK报文(第四次握手)和服务器端的FIN报文(第三次挥手)一来一回所需的最多的时间是2MSL。因此在2MSL之后，服务器端没有接受到消息，表明服务器端已经收到了ACK报文，因此客户端也可以安全关闭连接了。

### 什么是半连接

kernel中有两个队列，一个是半连接队列，一个是全连接队列,半连接指的是只接受到SYN报文的连接(处于SYN_RCVD状态的连接),全连接指的是已经完成三次握手的连接

半连接队列：

客户端发送SYN包，服务端收到后回复SYN+ACK后，服务端进入SYN_RCVD状态，这个时候的socket会放到半连接队列。

全连接队列：
当服务端收到客户端的ACK后，socket会从半连接队列移出到全连接队列。当调用accpet函数的时候，会从全连接队列的头部返回可用socket给用户进程。全连接队列中存放的是已完成TCP三次握手的过程，等待被处理的连接，在客户端及服务端的状态均为 ESTABLISHED

### TCP流量控制和拥塞控制

TCP提供可靠数据传输的方式(保证数据包的交付，完整性以及有序性)

3.  TCP拥塞控制和流量控制

  **流量控制**(使接收方和发送方之间的速度匹配),利用滑动窗口的方式

  - rwnd (接受窗口大小)
  - RecvBuffer (接收方缓存)
  - LastByteRevd (接收方最后一个接受到的字节)
  - LastByteRead (接收方上方应用层最后一个读取的字节)
  
  rwnd = RevBuffer - [LastByteRevd - LastByteRead]

rwnd就是接受方缓存的剩余空间，通过接收方讲rwnd发回给发送方，发送方就可以知道目前接收方还剩多少缓存，从而控制自己的速度

一种特殊情况是rwnd等于0时，而且此时接收方没有任何数据要发送给发送方，这时发送方就会被阻塞，因此TCP规范中规定了当接受方的接受窗口为0时，发送方继续发送一个只有一字节数据的报文段，来更新rwnd

**拥塞控制**
有三个问题
1. 当发送方感知到拥塞时,如何限制其发送速率
2. 如何感知网络拥塞
3. 当发送方感知到端到端的拥塞时,采用何种算法来改变其发送速率

问题1:当发送方感知到拥塞时,如何限制其发送速率

术语:
1. cwnd (拥塞窗口大小)
2. LastByteSent (发送方最后一个发送的字节)
3. LstByteAcked (发送方最后一个被确认的字节)

在发送方未确认的字节数为(LastByteSent - LstByteAcked),因此我们对这个数字进行限制,即可限制发送方的发送速率

应有以下式子成立

`LastByteSent - LstByteAcked <= min(cwnd, rwnd)`

问题2:如何感知网络拥塞

可以通过丢包来感知网络拥塞:丢包时指要么出现超时,要么收到了接受方的3个冗余ACK(快速重传机制)

问题3:当发送方感知到端到端的拥塞时,采用何种算法来改变其发送速率
拥塞控制算法包括三个部分: 1. 慢启动  2.拥塞避免 3. 快速恢复, 其中慢启动和拥塞避免时TCP的强制部分

**慢启动**

慢启动算法的思想是:从较小的发送速率开始试探,迅速提升发送速率(指数翻倍的方式)来找到一个合适的值

指数翻倍是指每收到一个ACK,则cwnd += MSS,即每个RTT内cwnd的值翻倍

如何结束这种指数增长?有三种方式

1. 当TCP发生丢包时,即检测到拥塞，TCP会将cwnd设置为1,重新开始慢启动,并记录慢启动阈值变量ssthresh = cwnd / 2
2. 当存在ssthresh变量时,当cwnd达到ssthresh时,继续指数增长是不妥当的,因此此时结束慢启动,进入拥塞避免阶段
3. 当检测到3个冗余ACK之后,TCP进入快速恢复状态

**拥塞避免**

当cwnd >= ssthresh时,此时cwnd的增长改为线性增长:即每个RTT只将cwnd的值增加1MSS

一种通用的办法时,当收到一个ACK时, `cwnd +=  MSS*(MSS/cwnd)`  `cwnd/MSS`可以理解成当前一次性发送的报文个数

结束拥塞避免:
1. 当出现超时时,ssthressh = cwnd/2, cwnd=1,转入慢启动
2. 当出现三个冗余ACK时, ssthresh = cwnd/2, cwnd = ssthresh + 3MSS,转入快速恢复

**快速恢复**
1. cwnd = cwnd +3MSS (因为收到了3个冗余ACK)
2. 重传重复ACK指定的数据包
3. 如果在收到重复ACK,cwnd+=1
4. 如果收到新的ACK,表明重传报文已经收到,此时将cwnd设置为ssthresh,并进入拥塞避免状态
5. 超时,ssthresh = cwnd/2, cwnd=1,转入慢启动

总结TCP的拥塞控制算法,具有加性增,乘性减的特点

### TCP的keep-alive机制

1. TCP连接在正常连接过程中连接异常中断后会发生什么？

2. TCP keep-alive

# 网络层

# 数据链路层




